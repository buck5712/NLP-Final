{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f30a3981",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-05-19T12:22:31.820456Z",
     "iopub.status.busy": "2022-05-19T12:22:31.820028Z",
     "iopub.status.idle": "2022-05-19T12:22:31.840771Z",
     "shell.execute_reply": "2022-05-19T12:22:31.839953Z"
    },
    "papermill": {
     "duration": 0.046415,
     "end_time": "2022-05-19T12:22:31.845582",
     "exception": false,
     "start_time": "2022-05-19T12:22:31.799167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/nycu-nlp110/sample.csv\n",
      "/kaggle/input/nycu-nlp110/fixed_test.csv\n",
      "/kaggle/input/nycu-nlp110/fixed_train.csv\n",
      "/kaggle/input/nycu-nlp110/fixed_valid.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c00709c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T12:22:31.873208Z",
     "iopub.status.busy": "2022-05-19T12:22:31.872847Z",
     "iopub.status.idle": "2022-05-19T12:22:33.893108Z",
     "shell.execute_reply": "2022-05-19T12:22:33.892258Z"
    },
    "papermill": {
     "duration": 2.033521,
     "end_time": "2022-05-19T12:22:33.896215",
     "exception": false,
     "start_time": "2022-05-19T12:22:31.862694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'NLP-Final'...\r\n",
      "remote: Enumerating objects: 53, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (53/53), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (42/42), done.\u001b[K\r\n",
      "remote: Total 53 (delta 11), reused 53 (delta 11), pack-reused 0\u001b[K\r\n",
      "Unpacking objects: 100% (53/53), 3.08 MiB | 4.22 MiB/s, done.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/buck5712/NLP-Final.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94437aaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T12:22:33.935584Z",
     "iopub.status.busy": "2022-05-19T12:22:33.935273Z",
     "iopub.status.idle": "2022-05-19T12:22:48.628443Z",
     "shell.execute_reply": "2022-05-19T12:22:48.627565Z"
    },
    "papermill": {
     "duration": 14.715641,
     "end_time": "2022-05-19T12:22:48.630628",
     "exception": false,
     "start_time": "2022-05-19T12:22:33.914987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/lib/python3.7/site-packages (from -r ./NLP-Final/requirements.txt (line 1)) (1.21.6)\r\n",
      "Requirement already satisfied: torch>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from -r ./NLP-Final/requirements.txt (line 2)) (1.11.0)\r\n",
      "Collecting transformers<4.0.0,>=3.5.1\r\n",
      "  Downloading transformers-3.5.1-py3-none-any.whl (1.3 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: sklearn in /opt/conda/lib/python3.7/site-packages (from -r ./NLP-Final/requirements.txt (line 4)) (0.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=0.4.0->-r ./NLP-Final/requirements.txt (line 2)) (4.2.0)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (4.63.0)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (2.27.1)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (3.6.0)\r\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (21.3)\r\n",
      "Collecting sentencepiece==0.1.91\r\n",
      "  Downloading sentencepiece-0.1.91-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (0.0.53)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (2021.11.10)\r\n",
      "Collecting tokenizers==0.9.3\r\n",
      "  Downloading tokenizers-0.9.3-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: protobuf in /opt/conda/lib/python3.7/site-packages (from transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (3.19.4)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from sklearn->-r ./NLP-Final/requirements.txt (line 4)) (1.0.2)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (3.0.7)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (2021.10.8)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (3.3)\r\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (2.0.12)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (1.26.8)\r\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (8.0.4)\r\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (1.16.0)\r\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (1.0.1)\r\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn->-r ./NLP-Final/requirements.txt (line 4)) (1.7.3)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->sklearn->-r ./NLP-Final/requirements.txt (line 4)) (3.1.0)\r\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click->sacremoses->transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (4.11.3)\r\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click->sacremoses->transformers<4.0.0,>=3.5.1->-r ./NLP-Final/requirements.txt (line 3)) (3.7.0)\r\n",
      "Installing collected packages: tokenizers, sentencepiece, transformers\r\n",
      "  Attempting uninstall: tokenizers\r\n",
      "    Found existing installation: tokenizers 0.12.1\r\n",
      "    Uninstalling tokenizers-0.12.1:\r\n",
      "      Successfully uninstalled tokenizers-0.12.1\r\n",
      "  Attempting uninstall: sentencepiece\r\n",
      "    Found existing installation: sentencepiece 0.1.96\r\n",
      "    Uninstalling sentencepiece-0.1.96:\r\n",
      "      Successfully uninstalled sentencepiece-0.1.96\r\n",
      "  Attempting uninstall: transformers\r\n",
      "    Found existing installation: transformers 4.18.0\r\n",
      "    Uninstalling transformers-4.18.0:\r\n",
      "      Successfully uninstalled transformers-4.18.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "allennlp 2.9.3 requires transformers<4.19,>=4.1, but you have transformers 3.5.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -r ./NLP-Final/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acf8bacb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T12:22:48.668539Z",
     "iopub.status.busy": "2022-05-19T12:22:48.668279Z",
     "iopub.status.idle": "2022-05-19T12:22:49.341517Z",
     "shell.execute_reply": "2022-05-19T12:22:49.340668Z"
    },
    "papermill": {
     "duration": 0.694867,
     "end_time": "2022-05-19T12:22:49.343693",
     "exception": false,
     "start_time": "2022-05-19T12:22:48.648826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSA-PyTorch-master.zip  dependency_graph.py  requirements_rtx30.txt\r\n",
      "LICENCE\t\t\t infer_example.py     train.py\r\n",
      "README.md\t\t layers\t\t      train_k_fold_cross_val.py\r\n",
      "data_utils.py\t\t models\r\n",
      "datasets\t\t requirements.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls ./NLP-Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2826a2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T12:22:49.382110Z",
     "iopub.status.busy": "2022-05-19T12:22:49.381860Z",
     "iopub.status.idle": "2022-05-19T12:22:50.049781Z",
     "shell.execute_reply": "2022-05-19T12:22:50.048803Z"
    },
    "papermill": {
     "duration": 0.689741,
     "end_time": "2022-05-19T12:22:50.052087",
     "exception": false,
     "start_time": "2022-05-19T12:22:49.362346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP-Final  __notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b551cd54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T12:22:50.091844Z",
     "iopub.status.busy": "2022-05-19T12:22:50.091361Z",
     "iopub.status.idle": "2022-05-19T12:23:46.744023Z",
     "shell.execute_reply": "2022-05-19T12:23:46.743109Z"
    },
    "papermill": {
     "duration": 56.674845,
     "end_time": "2022-05-19T12:23:46.746377",
     "exception": false,
     "start_time": "2022-05-19T12:22:50.071532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch==1.4.0\r\n",
      "  Downloading torch-1.4.0-cp37-cp37m-manylinux1_x86_64.whl (753.4 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.4/753.4 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torch\r\n",
      "  Attempting uninstall: torch\r\n",
      "    Found existing installation: torch 1.11.0\r\n",
      "    Uninstalling torch-1.11.0:\r\n",
      "      Successfully uninstalled torch-1.11.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pytorch-lightning 1.6.3 requires torch>=1.8.*, but you have torch 1.4.0 which is incompatible.\r\n",
      "kornia 0.5.8 requires torch>=1.6.0, but you have torch 1.4.0 which is incompatible.\r\n",
      "fastai 2.6.3 requires torch<1.12,>=1.7.0, but you have torch 1.4.0 which is incompatible.\r\n",
      "fairscale 0.4.6 requires torch>=1.8.0, but you have torch 1.4.0 which is incompatible.\r\n",
      "allennlp 2.9.3 requires torch<1.12.0,>=1.6.0, but you have torch 1.4.0 which is incompatible.\r\n",
      "allennlp 2.9.3 requires transformers<4.19,>=4.1, but you have transformers 3.5.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed torch-1.4.0\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f404d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-19T12:23:47.056756Z",
     "iopub.status.busy": "2022-05-19T12:23:47.056422Z",
     "iopub.status.idle": "2022-05-19T12:24:22.188670Z",
     "shell.execute_reply": "2022-05-19T12:24:22.187712Z"
    },
    "papermill": {
     "duration": 35.291241,
     "end_time": "2022-05-19T12:24:22.190825",
     "exception": false,
     "start_time": "2022-05-19T12:23:46.899584",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 3.00MB/s]\r\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 133kB/s]\r\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:14<00:00, 31.2MB/s]\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"./NLP-Final/train.py\", line 303, in <module>\r\n",
      "    main()\r\n",
      "  File \"./NLP-Final/train.py\", line 298, in main\r\n",
      "    ins = Instructor(opt)\r\n",
      "  File \"./NLP-Final/train.py\", line 52, in __init__\r\n",
      "    self.trainset = ABSADataset(opt.dataset_file['train'], tokenizer)\r\n",
      "  File \"/kaggle/working/NLP-Final/data_utils.py\", line 128, in __init__\r\n",
      "    fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\r\n",
      "FileNotFoundError: [Errno 2] No such file or directory: './datasets/semeval14/Restaurants_Train.xml.seg'\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python ./NLP-Final/train.py --model_name bert_spc --dataset restaurant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375d8918",
   "metadata": {
    "papermill": {
     "duration": 0.142349,
     "end_time": "2022-05-19T12:24:22.470338",
     "exception": false,
     "start_time": "2022-05-19T12:24:22.327989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 119.492644,
   "end_time": "2022-05-19T12:24:23.131363",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-05-19T12:22:23.638719",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
